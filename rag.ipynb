{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a RAG application from scratch\n",
    "\n",
    "Here is a high-level overview of the system we want to build:\n",
    "\n",
    "<img src='images/system1.png' width=\"1200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the environment variables we need to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bfb1351d-6ded-46c2-9b68-203d6553b4ec'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# This is the YouTube video we're going to use.\n",
    "YOUTUBE_VIDEO = \"https://www.youtube.com/watch?v=cdiD-9MMpb0\"\n",
    "\n",
    "PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model\n",
    "Let's define the LLM model that we'll use as part of the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the model by asking a simple question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The Los Angeles Dodgers won the World Series during the COVID-19 pandemic in 2020.', response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 21, 'total_tokens': 40}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}, id='run-055b9f25-ff71-4aec-8cec-de474898378c-0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"What MLB team won the World Series during the COVID-19 pandemic?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result from the model is an `AIMessage` instance containing the answer. We can extract this answer by chaining the model with an [output parser](https://python.langchain.com/docs/modules/model_io/output_parsers/).\n",
    "\n",
    "Here is what chaining the model with an output parser looks like:\n",
    "\n",
    "<img src='images/chain1.png' width=\"1200\">\n",
    "\n",
    "For this example, we'll use a simple `StrOutputParser` to extract the answer as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Los Angeles Dodgers won the World Series during the COVID-19 pandemic, defeating the Tampa Bay Rays in the 2020 World Series.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser\n",
    "chain.invoke(\"What MLB team won the World Series during the COVID-19 pandemic?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing prompt templates\n",
    "\n",
    "We want to provide the model with some context and the question. [Prompt templates](https://python.langchain.com/docs/modules/model_io/prompts/quick_start) are a simple way to define and reuse prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: \\nAnswer the question based on the context below. If you can\\'t \\nanswer the question, reply \"I don\\'t know\".\\n\\nContext: Mary\\'s sister is Susana\\n\\nQuestion: Who is Mary\\'s sister?\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt.format(context=\"Mary's sister is Susana\", question=\"Who is Mary's sister?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now chain the prompt with the model and the output parser.\n",
    "\n",
    "<img src='images/chain2.png' width=\"1200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Susana'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "chain.invoke({\n",
    "    \"context\": \"Mary's sister is Susana\",\n",
    "    \"question\": \"Who is Mary's sister?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining chains\n",
    "\n",
    "We can combine different chains to create more complex workflows. For example, let's create a second chain that translates the answer from the first chain into a different language.\n",
    "\n",
    "Let's start by creating a new prompt template for the translation chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate {answer} to {language}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a new translation chain that combines the result from the first chain with the translation prompt.\n",
    "\n",
    "Here is what the new workflow looks like:\n",
    "\n",
    "<img src='images/chain3.png' width=\"1200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mar√≠a tiene una hermana.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "translation_chain = (\n",
    "    {\"answer\": chain, \"language\": itemgetter(\"language\")} | translation_prompt | model | parser\n",
    ")\n",
    "\n",
    "translation_chain.invoke(\n",
    "    {\n",
    "        \"context\": \"Mary's sister is Susana. She doesn't have any more siblings.\",\n",
    "        \"question\": \"How many sisters does Mary have?\",\n",
    "        \"language\": \"Spanish\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribing the YouTube Video\n",
    "\n",
    "The context we want to send the model comes from a YouTube video. Let's download the video and transcribe it using [OpenAI's Whisper](https://openai.com/research/whisper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import whisper\n",
    "from pytube import YouTube\n",
    "\n",
    "\n",
    "# Let's do this only if we haven't created the transcription file yet.\n",
    "if not os.path.exists(\"transcription.txt\"):\n",
    "    youtube = YouTube(YOUTUBE_VIDEO)\n",
    "    audio = youtube.streams.filter(only_audio=True).first()\n",
    "\n",
    "    # Let's load the base model. This is not the most accurate\n",
    "    # model but it's fast.\n",
    "    whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        file = audio.download(output_path=tmpdir)\n",
    "        transcription = whisper_model.transcribe(file, fp16=False)[\"text\"].strip()\n",
    "\n",
    "        with open(\"transcription.txt\", \"w\") as file:\n",
    "            file.write(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the transcription and display the first few characters to ensure everything works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'US. Citizenship Non-Precedent Decision of the\\n\\n \\n\\nand Immigration Administrative Appeals Office\\nServ'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"extracted_text.txt\") as file:\n",
    "    transcription = file.read()\n",
    "\n",
    "transcription[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the entire transcription as context\n",
    "\n",
    "If we try to invoke the chain using the transcription as context, the model will return an error because the context is too long.\n",
    "\n",
    "Large Language Models support limitted context sizes. The video we are using is too long for the model to handle, so we need to find a different solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    chain.invoke({\n",
    "        \"context\": transcription,\n",
    "        \"question\": \"was this case denied?\"\n",
    "    })\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the transcription\n",
    "\n",
    "Since we can't use the entire transcription as the context for the model, a potential solution is to split the transcription into smaller chunks. We can then invoke the model using only the relevant chunks to answer a particular question:\n",
    "\n",
    "<img src='images/system2.png' width=\"1200\">\n",
    "\n",
    "Let's start by loading the transcription in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"US. Citizenship Non-Precedent Decision of the\\n\\n \\n\\nand Immigration Administrative Appeals Office\\nServices\\nIn Re: 21169180 Date: SEP. 08, 2022\\n\\nAppeal of Vermont Service Center Decision\\n\\nForm I-129, Petition for Nonimmigrant Worker (Extraordinary Ability ‚Äî O)\\n\\nThe Petitioner, a skydiving center, seeks to temporarily employ the Beneficiary as a skydiving\\ninstructor, coach, and videographer. To do so, the Petitioner seeks to classify the Beneficiary as an\\nO-1 nonimmigrant of extraordinary ability in athletics. This classification is available to individuals\\nwho can demonstrate their extraordinary ability through sustained national or international acclaim\\nand whose achievements have been recognized in the field through extensive documentation. See\\nImmigration and Nationality Act (the Act) section 101(a)(15)(O)(i), 8 U.S.C. ¬ß 1101(a)(15)(O)Q).\\n\\nThe Director of the Vermont Service Center denied the petition, concluding that the record did not\\ncontain evidence of the Beneficiary‚Äôs receipt of a major, internationally recognized award, at least\\nthree of eight listed categories of documents, or comparable evidence of his eligibility. 8 C.F.R.\\n¬ß 214.2(0)(3)(iii)(A)-(C).\\n\\nIn these proceedings, it is the Petitioner‚Äôs burden to establish eligibility for the requested benefit.\\nSection 291 of the Act, 8 U.S.C. ¬ß 1361. Upon de novo review, we will dismiss the appeal.\\n\\nI. LAW\\n\\nAs relevant here, section 101(a)(15)(O)(i) of the Act establishes O-1 classification for an individual\\nwho has extraordinary ability in the sciences, arts, education, business, or athletics that has been\\ndemonstrated by sustained national or international acclaim, whose achievements have been\\nrecognized in the field through extensive documentation, and who seeks to enter the United States to\\ncontinue work in the area of extraordinary ability. Department of Homeland Security (DHS)\\nregulations define ‚Äúextraordinary ability in the field of science, education, business, or athletics‚Äù as ‚Äúa\\nlevel of expertise indicating that the person is one of the small percentage who have arisen to the very\\ntop of the field of endeavor.‚Äù 8 C.F.R. ¬ß 214.2(0)(3)(ii).\\n\\nNext, DHS regulations set forth alternative evidentiary criteria for establishing a beneficiary‚Äôs\\nsustained acclaim and the recognition of achievements. A petitioner must submit evidence either of\\n‚Äúa major, internationally recognized award, suchas a Nobel Prize,‚Äù or of at least three of eight listed\\ncategories of documents. 8 C.F.R. ¬ß 214.2(0)(3)@ii)(A)-(B). If the petitioner demonstrates that the\\n\\ni a\\n\\n \\n\\ni MON a a I a ig I\\n\\x0c\\nsubmit comparable evidence in order to establish the individual‚Äôs eligibility. 8 CFR.\\n¬ß 214.2(0)(3)Giii(C).\\n\\nThe submission of documents satisfying the initial evidentiary criteria does not, in and of itself,\\nestablish eligibility for O-1 classification. See 59 Fed. Reg. 41818, 41820 (Aug. 15, 1994) (‚ÄúThe\\nevidence submitted by the petitioner is not the standard for the classification, but merely the\\nmechanism to establish whether the standard has been met.‚Äù). Accordingly, where a petitioner\\nprovides qualifying evidence satisfying the initial evidentiary criteria, we will determine whether the\\ntotality of the record and the quality of the evidence shows sustained national or international acclaim\\nsuch that the individual is among the small percentage at the very top of the field of endeavor. See\\nsection 101(a)(15)(o)() of the Act and 8 C.F.R. ¬ß 214.2(0)(3)(ii), (iii). !\\n\\nIl. ANALYSIS\\n\\nThe Beneficiary indicates current employment as a skydiving instructor in Chile since 2019 and\\nprevious experience competing in the sport ir since 2016. The Petitioner seeks to employ\\nthe Beneficiary as a skydiving instructor, coach, and videographer for a period of approximately 43\\nmonths.? The Petitioner‚Äôs Working Agenda for 2021 to 2024 indicates the Beneficiary‚Äôs duties will\\ninclude coaching its skydiving students in multiple disciplines and competing in several national\\ntournaments.\\n\\nA. Eligibility Claims\\n\\nBecause the Petitioner did not establish that the Beneficiary has received a major, internationally\\nrecognized award, it must satisfy at least three of the alternate regulatory criteria at 8 C.F.R.\\n¬ß 214.2(0)(3)Gii)(B)(/)-(8). Within its initial submission, the Petitioner claimed that the Beneficiary\\nmet four of the cight regulatory criteria at 8 C.F.R. ¬ß 214.2(0)(3)(iii)(B): awards at 8 C.F.R.\\n¬ß 214.2(0)(3)Gii)(B)(), memberships at 8 C.F.R. ¬ß 214.2(0)(3)(iii)(B)(2), published material at\\n8C.F.R. ¬ß 214.2(0)(3)Gii)(B)(3), and employment in a critical or essential capacity at 8 C.F.R.\\n¬ß 214.2(0)(3)Gii)(B)\\\\(7). In response to the Director‚Äôs request for further evidence (RFE), the\\nPetitioner requested that the Director consider comparable evidence for one additional criterion,\\njudging at 8 C.F.R. ¬ß 214.2(0)(3)(iii)(B)(4).\\n\\nThe Director subsequently denied the petition, determining that the Petitioner established that the\\nBeneficiary satisfied only one of the initial evidentiary criteria, awards under 8 C.F.R.\\n¬ß 214.2(0)(3)Gii)(B)()._ The record indicates that the Beneficiary placed third in the\\n\\ncategory at the 20 National Parachuting Championships. Accordingly, the Petitioner\\ndemonstrated that the Ben√©ficiary satisfies this criterion, and we agree with the Director‚Äôs findings for\\nthis criterion.\\n\\n' See also Matter of Chawathe, 25 1&N Dec. 369,376 (AAO 2010), in which we held that, ‚Äútruth is to be determined not\\nby the quantity of evidencealonebutby its quality.‚Äù\\n\\n? Pursuant to the regulations at 8 C.F.R. 214.2(0)(6)(iii), an approved petition for a noncitizen classified under section\\n101(a)(15)(O)(@) of the Act shall be valid for a period of time determined by the Director to be necessary to accomplish\\nthe event oractivity, not to exceed 3 years.\\n\\x0c\\nOn appeal, the Petitioner maintains the Beneficiary‚Äô seligibility for four additional criteria. In addition,\\nfor the first time the Petitioner contends that the Beneficiary meets two further criteria, scholarly\\narticles at 8 C.F.R. ¬ß 214.2(0)(3)(iii)(B)(6) and high salary at 8 C.F.R. ¬ß 214.2(0)(3)(iii)(B)(8);\\nhowever, as the Petitioner did not make these claims before the Director, either at the time it filed the\\npetition or in response to the Director‚Äôs RFE, we will not consider these claims in our adjudication of\\nthis appeal. See Matter of Soriano, 19 I&N Dec. 764, 766 (BIA 1988) (providing that if ‚Äúthe petitioner\\nwas put on notice of the required evidence and given a reasonable opportunity to provide it for the\\nrecord before the denial, we will not consider evidence submitted on appeal for any purpose‚Äù and that\\n‚Äúwe will adjudicate the appeal based on the record of proceedings‚Äù before the Chief); see also Matter\\nof Obaigbena, 19 I&N Dec 533 (BIA 1988).\\n\\nFor the reasons discussed below, the Petitioner did not establish that the Beneficiary meets the\\nrequirements of at least three criteria.\\n\\nB. Evidentiary Criteria\\n\\nDocumentation of the alien‚Äôs membership in associations in the field for which\\nclassification is sought, which require outstanding achievements of their members as\\njudged by recognized national or international experts in their disciplines or fields.\\n8 C.F.R. ¬ß 214.2(0)(3)Gii)(B)(2).\\n\\nThe Petitioner claimed that the Beneficiary satisfies this criterion based upon his membership in the\\n\\nParachute Association[_____] and the ____] Parachute FederationL____] his\\nskydiving qualifications, and his selection to participate in a Panam Sports Organization (PSO) High\\nPerformance Coaches Certificate | training course.\\n\\nFirst, regarding the Beneficiary‚Äôs memberships, the Petitioner provided the Beneficiary‚ÄôsL__]\\nmembership card. In addition, it submitted several letters containing information relevant to this\\ncriterion. For instance, a ‚Äúno objection‚Äù letter dated January 2021 fron. =i the\\n\\nin satisfaction of the consultation requirement at 8 C.F.R. ¬ß 214.2(0)(5)(ii)(A), also provides that the\\nBeneficiary is a member of the | An additional letter fromL___| provided two\\nwebsites which he asserts contain ‚Äúcriteria for membership and ratings,‚Äù but his letter does not mention\\nthe requirements for membership in the organization, nor did the Petitioner provide screenshots of the\\nwebsites supporting a claim that thel requires outstanding achievements of its members, as\\njudged by recognized national or international experts in the Beneficiary‚Äôs field or an allied one.\\n\\nFurther, letters from LT an qd representatives of thel__ | confirm the\\n\\nBeneficiary‚Äôs membership in that organization and include some of his competitive achievements in\\nthe sport A leter froml off the\\n\\nBeneficiary‚Äôs employer, mentions the Beneficiary‚Äôs ‚Äúinternational experience in Championships and\\n\\ndifferent skydiveassociations or federations,‚Äù but does not specify in which associations or federations\\nthe Beneficiary has membership. An additional letter from provides that the\\nenefisiany is also a board member of but it does not assert that\\n\\nrequires outstanding achievements, as judged by recognized national\\nor international experts, to be appointed to its board.\\n\\x0c\\nmembership in associations in the field ror whicn Classification is sougnt, which require outstanding\\nachievements of their members, as judged by recognized national or international experts in their\\ndisciplines or fields.‚Äù Thus, the burden remains with the Petitioner to not only establish the\\nBeneficiary‚Äôs membership but to also demonstrate that those memberships require outstanding\\nachievements, as judged by recognized national or international experts in the field__Here, although\\nthe evidence presented confirms the Beneficiary‚Äôs membership inL___] and and board\\nmembership in the Petitioner did not point out which, if any,\\nevidence displays the membership requirements and explain how membership in those organizations\\nrequires outstanding achievements and reflects that judging is comprised of recognized national or\\ninternational experts.\\n\\n \\n\\nNext, pertaining to the Beneficiary‚Äôs skydiving qualifications, the Petitioner provided documentation\\nregarding his certifications, ratings, and endorsements, including 2017 Coach Rating Course\\ncompletion certificate; 2019 Skydiving Association parachutist Instructor D and AFF and\\nTA Endorsements; 202 || License D and coach certifications and AFF 1 and TAN | ratings;\\n2021L___ instructor rating certificate; and International Parachutist Certificate for\\nCertificate D and Packer B. However, he has not explainedhow achieving those certifications, ratings,\\nand endorsements conveyed membership in an association, as required by the plain language of the\\nregulation at 8 C.F.R. ¬ß 214.2(0)(3)(iti)(B)(2).\\n\\n  \\n\\nMoreover, the Petitioner asserted that the Beneficiary‚Äôs selection to participate in a PSO High\\nPerformance Coaches Certificate | training course satisfies this criterion. It provided a letter dated\\nMarch 2021 from of the Chilean Skydiving Federation and\\nmember of the Chilean National Olympic Committee, who confirms the Beneficiary‚Äôs anticipated\\nparticipation in the training course, designed for ‚Äúcoaches, technicians and fitness trainers who work\\nin high-performance‚Äù who are ‚Äúchosen by [the] National Olympic Committee of each country.‚Äù It\\nalso provided promotional material from PSO showing the training course was scheduled for March\\nto November 2021.3 However, the Petitioner cannot rely on those materials to establish the\\nBeneficiary‚Äôs eligibility at the time of filing this petition in April 2021. A petitioner must establish\\nthat all eligibility requirements for the immigration benefit have been satisfied from the time of the\\nfiling and continuing through adjudication. 8 C.F.R. ¬ß 103.2(b)(1); see also Matter of Katigbak,\\n141I&N Dec. 45, 49 (Comm‚Äôr 1971). Regardless, the Petitioner has not explained how the\\nBeneficiary‚Äôs participation in the training course conveys membership in an association, as required\\nby the plain language of the regulation at 8 C.F.R. ¬ß 214.2(0)(3 )(iii)(B)(2).\\n\\n \\n\\nThe documentation submitted further included general skydiving information, such as an excerpt from\\nthe 2019. Parachute Federation Industry Standard Training Operations Manual (TOM)\\npertaining to suggested training for[____] candidates; the table of contents of the 2021 FAI\\nSporting Code, Section 5 ‚Äî Skydiving; an article from https://ww.perrisblog.onchat.io entitled ‚ÄúHow\\nto Become a Skydiving Instructor;‚Äù a piece from www.skydivecarolina.com entitled ‚ÄúHow Much\\nExperience Do Tandem Skydive Instructors Have;‚Äù and an item from www.skydivecarolina.com\\n\\n3 The Petitioner also submitted screenshots from www.panamsports.org fora July 2020 course entitled ‚ÄúSports Psychology\\n\\nLTT A. Te PN ee be ke ta Te At. KR. Lee kL ed. ek nt a cc ca\\n\\x0c\\nand the minimum number oT skydives required Tor each, being 25, OU, ZUU, and OUY, respectively.\\nHowever, this evidence does not demonstrate the membership requirements of any associations.\\n\\nOn appeal, the Petitioner_provides letters from skydiving instructor|________] with The\\nParachute School of skydiving instructor with\\n\\nskydiver skydive jump pilot! additional letters from\\nand and\\nadditional materials from the websites of the As the Petitioner did not present these\\ndocuments to the Director in its initial filing or in response to the Director‚Äôs RFE, we will not consider\\nthem in our adjudication of this appeal. Soriano, 19 I&N Dec. at 766; see also Obaighena, 19 I&N\\nDec. at 533.\\n\\n    \\n\\n       \\n\\n  \\n\\nFinally, with respectto the Beneficiary‚Äôs third-place finish atthe 201 g___]National Parachuting\\nChampionships, the Petitioner emphasizes that in her letters, thls stated the\\nBeneficiary‚Äôs results were scored ‚Äúby six L__}rated judges.‚Äù However, the Petitioner has not\\nexplained how the Beneficiary achieving third place in a national skydiving championship conveyed\\nmembership in an association, as required by the plain language of the regulation at 8 C.F.R.\\n¬ß 214.2(0)(3)(iii)(B)\\\\(2). The Petitioner submitted the same evidence in_ support of the awards\\ncriterion, which was appropriate given the nature of the [| National Parachuting\\nChampionships as a competition in the Beneficiary‚Äôs field rather than an association in his field.\\n\\nFor the reasons outlined above, the record does not reflect that the Petitioner submitted documentation\\nsufficient to demonstrate that the Beneficiary meets this criterion.\\n\\nPublished material in professional or major trade publications or major media about\\nthe alien, relating to the alien‚Äôs work in the field for which classification is sought,\\nwhich shall include the title, date, and author of such published material, and any\\nnecessary translation. 8 C.F.R. ¬ß 214.2(0)(3)(ili)(B)(3).\\n\\nThe Director determined that the record does not reflect that the Petitioner submitted sufficient\\ndocumentary evidence demonstrating that the Beneficiary meets this criterion.*\\n\\nThe Petitioner submitted articles dated between 2016 to 2021 pertaining to the Beneficiary from the\\nprint editions of the magazines|_____| Skydiver Magazine and Parachutist. We find that the\\nappearance of the Beneficiary‚Äô snameand photograph in the 2019 issueof, LT Skydiver Magazine\\ndoes notrise to the level of an article about the Beneficiary. The magazine reported the individual and\\nteam results at the 20 ig National Parachuting Championships. While the article supports the\\n\\n4 The Director determined that the Petitioner did not satisfy this criterion, in part, because the articles submitted did not\\n‚Äúidentify the beneficiary as a person who has risen to the very top of thefield of skydiving.‚Äù However, this consideration\\ndoes not relate to whether the Petitioner has met theplain language of this criterion. Ifthe Petitioner had satisfied at kast\\nthree criteria, which it did not, then we would have analyzed the published materials as part of the totality of the evidence\\nto determine if the Beneficiary‚Äôs successes are sufficient to establish that he has extraordinary ability in the field of\\nendeavor. Although we need not conduct such an analysis in this case, we briefly note that we do not find the record\\n\\neg ae a ee ll wt\\n\\n  \\n\\nwe\\n\\x0c\\nPetitioner‚Äôs claim of the Beneficiary‚Äôs bronze medal at this national event, the Beneficiary was not\\nidentified by name in a caption to the photograph, and the photograph appears to be one of many\\nphotographs of the competition‚Äôs individual and team winners. In addition, we note that while the\\nBeneficiary‚Äôs receipt of tandem coach, AFF, and tandem-instructor ratings, and A, C, and D licenses\\nhave been reported in the above-referenced magazines, mere mentions of the Beneficiary‚Äôs name in a\\nlist of rating, licensing, or tournament results cannot be considered articles about the Beneficiary.\\nArticles that are not about a noncitizen do not fulfill this regulatory criterion. Cf Negro-Plumpe v. Okin,\\n2:07-CV-820-ECR-RJJ at *1, *7 (D. Nev. Sept. 8, 2008) (upholding a finding that articles regarding a\\nshow are not about the actor).\\n\\nThe Petitioner also provided a screenshot dated September 2020 from the Facebook page of The\\nRating Center with a photograph of the Beneficiary at his employer, and\\nthe caption ‚ÄúCongratulations to United States Parachute Association\\nInstructor [the Beneficiary]!‚Äù Another screenshot from the Facebook page of the\\nParachute Federation dated 2016 contains the Beneficiary‚Äôs name anda photographof hima\\nThe Petitioner, however, did not provide supporting evidence indicating that those\\nFacebook pages or the print editions ofL___]Skydiver Magazine or Parachutist qualify as major\\ntrade publications or major media. Although the Petitioner submitted an email from the editor-\\npublisher ofL__] Skydiver Magazine, stating that the final print edition of\\nthe magazine in 2020 had an average circulation of 3000, the record does not contain evidence\\nshowing the circulation of Lo | skydiver Magazine relative to othel_____] media or trade\\nmagazines, to demonstrate the publication constitutes a major trade publication or major medium. In\\naddition, we note that none of the above-mentioned articles identify the author.\\n\\n   \\n \\n  \\n\\nMoreover, the Petitioner submitted a YouTube screenshot of a video posted | an\\norganization that provides skydiving experiences to cancer patients and survivors. The video reflected\\na two-minute interview of the Beneficiary in 2020. Although the Petitioner provided a transcription\\nof the video, it did not demonstrate published material about the Beneficiary relating to his work.\\nRather, transcription indicates that the Beneficiary was interviewed about skydive landings. The\\nPetitioner also did not establish the YouTube channel represents a major medium.\\n\\nFor the above reasons, the Petitioner has not established that the Beneficiary satisfies this criterion.\\n\\nEvidence of the alien‚Äôs participation ona panel, or individually, as a judge of the work\\nof others in the same or in an allied field of specialization to that for which\\nclassification is sought. 8 C.F.R. ¬ß 214.2(0)(3)(iii(B)(4).\\n\\nThe Petitioner did not initially claim cligibility for this criterion. Within its response to the Director's\\nRFE, the Petitioner argued that we should consider comparable evidence for this criterion. As\\nmentioned above, the regulation at 8 C.F.R. 214.2(0)(3)(iii)(C) provides that ‚ÄúCijf the criteria in\\nparagraph (0)(3)(iii) of this section do not readily apply to the beneticiary‚Äôs occupation, the petitioner\\nmay submit comparable evidence in orderto establish the beneficiary‚Äôs cligibility.‚Äù5 Thus,a petitioner\\n\\n \\n\\n* Petitioners should submit evidence outlined in the evidentiary criteria if the criteria readily apply to the beneficiary‚Äôs\\noccupation. However, if the petitioner establishes that a particular criterion is not readily applicable to the beneticiary‚Äôs\\n\\x0c\\nmust demonstrate why the regulatory criterion does not pertain to a beneficiary‚Äôs occupation and how\\nthe evidence submitted is ‚Äúcomparable‚Äù to the objective evidence required at 8 C.F.R.\\n¬ß 214.2(0)(3)(iii).\\n\\nWithin its RFE response, the Petitioner contended that the Beneficiary worked as a judge ‚Äúwith other\\n\\nworld-renowned skydiving judges‚Äù in October 2016 when he ‚Äúwas invited to judge other skydiving\\nathletes alongside EL ane(‚Äî‚Äî‚Äî‚Äîdat‚Ç¨ SS\\nSkydiving Championships.‚Äù The Petitioner submitted an email dated October 2016 that appears to be\\nfrom Co | addressed to the Beneficiary and others, referencing ‚Äúthe upcoming\\nChampionships‚Äù and ‚Äòaccommodation for the five ofus. .. for the Saturday night (12th November),‚Äù\\nand stating as follows:\\n\\n.... [believe registrations have been received for for 4 way, CF (not sure whether 2 or 4 way)\\nand accuracy. Will confirm the events during the week before the event.\\n\\nWe'll be using InTime so can you please bring a Windows based computer...\\n\\nLook forward to seeing you atl\\n\\nThe Petitioner also provided several pages from the 2008 | Parachute Federation| _|\\nJudges‚Äô Handbook, screenshots from the website www. fai.org, and a screenshot that it claims is from\\nthe website asserting that these materials show the judging criteria, and that\\n\\nand are skydiving judges who are ‚Äúexceptional in their fields.‚Äù\\n\\nAs noted by the Director, in order to meet this criterion, the Petitioner must show that the Beneficiary\\nhas not only been invited to judge the work of others, but also that he actually participated in the\\njudging of the work of others in the same or allied field of specialization. Here, the Petitioner has not\\npresented corroborating documentation showing that the Beneficiary actually participated in judging\\nskydiving athletes, and the events_at which the Beneficiary judged, to show that he actually\\nparticipated as a judge for the 2016 [State Skydiving Championships, as claimed.\\n\\nIn addition, the Petitioner has notasserted or established that Skydive coaches or instructors are unable\\nto participate on a panel, or individually, as a judge of the work of others in the same or in an allied\\nfield. The fact that the Beneficiary did not participate in judging is not evidence that the criterion does\\nnotapply to his occupation. Further, the Petitioner did not demonstrate that the statements in the letter\\nof support from ‚Äîi@d or the screenshots of judging criteria are equivalent to\\nparticipation on a panel, or individually, as a judge of the work of others in the same or in an allied\\nfield. Accordingly, the Petitioner has not established that this criterion does not apply to the\\nBeneficiary‚Äôs occupation, nor has it shown that the documentation submitted reflects the same caliber\\nof experience as participating on a panel, or individually, as a judge of the work of others in the\\nBeneficiary‚Äôs field.\\n\\noccupation, the petitioner may then use the compamble evidence provision to submit additional evidence that is not\\nspecifically described in that criterion but is comparable to that criterion. See 2 USCIS Policy Manual M.A(O),\\nhttps://www.uscis.gov/policy manual.\\n\\x0c\\nIll. CONCLUSION\\n\\nThe Petitioner has not submitted evidence that the Beneficiary has received a major, internationally\\nrecognized award pursuant to 8 C.F.R. ¬ß 214.2(0)(3){ii1)(A). Further, although the Petitioner\\nestablished that the Beneficiary met the awards criterion at 8 C.F.R. ¬ß 214.2(0)(3)(i1i)(B)(J), it did not\\nestablish that he meets the criteria relating to memberships in associations, published materials, and\\njudging. Although the Petitioner maintains the Beneficiary‚Äôs eligibility for an additional criterion on\\nappeal, relating to having been employed in a critical or essential capacity for distinguished\\norganizations and establishments at 8 C.F.R. ¬ß 214.2(0)(3)(iii)(B)({7), we need notreach this additional\\nground. As the Petitioner cannot fulfill the initial evidentiary requirement of three criteria under\\n8 C.F.R. ¬ß 214.2(0)(3 \\\\iii)(B), we reserve this issue.6 Consequently, the Petitioner has not established\\nthe Beneficiary's eligibility for the O-1 visa classification as an individual of extraordinary ability in\\nathletics. The appeal will be dismissed for the above stated reasons, with each considered as an\\nindependent and alternate basis for the decision.\\n\\nORDER: The appeal is dismissed.\\n\\n6 See INS v. Bagumasbad, 429 U.S. 24, 25-26 (1976) (stating that, like courts, federal a gencies are not generally required\\nto make findings and decisions unnecessary to the results they reach); see also Matter of L-A-C-, 26 1&N Dec. 516, 1.7\\n(declining to reach alternative issues on appeal where an applicant is otherwise ineligible).\\n\\x0c\\n\", metadata={'source': 'extracted_text.txt'})]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"extracted_text.txt\")\n",
    "text_documents = loader.load()\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different ways to split a document. For this example, we'll use a simple splitter that splits the document into chunks of a fixed size. Check [Text Splitters](https://python.langchain.com/docs/modules/data_connection/document_transformers/) for more information about different approaches to splitting documents.\n",
    "\n",
    "For illustration purposes, let's split the transcription into chunks of 100 characters with an overlap of 20 characters and display the first few chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='US. Citizenship Non-Precedent Decision of the', metadata={'source': 'extracted_text.txt'}),\n",
       " Document(page_content='and Immigration Administrative Appeals Office\\nServices\\nIn Re: 21169180 Date: SEP. 08, 2022', metadata={'source': 'extracted_text.txt'}),\n",
       " Document(page_content='Appeal of Vermont Service Center Decision', metadata={'source': 'extracted_text.txt'}),\n",
       " Document(page_content='Form I-129, Petition for Nonimmigrant Worker (Extraordinary Ability ‚Äî O)', metadata={'source': 'extracted_text.txt'}),\n",
       " Document(page_content='The Petitioner, a skydiving center, seeks to temporarily employ the Beneficiary as a skydiving', metadata={'source': 'extracted_text.txt'})]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "text_splitter.split_documents(text_documents)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our specific application, let's use 1000 characters instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "documents = text_splitter.split_documents(text_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the relevant chunks\n",
    "\n",
    "Given a particular question, we need to find the relevant chunks from the transcription to send to the model. Here is where the idea of **embeddings** comes into play.\n",
    "\n",
    "An embedding is a mathematical representation of the semantic meaning of a word, sentence, or document. It's a projection of a concept in a high-dimensional space. Embeddings have a simple characteristic: The projection of related concepts will be close to each other, while concepts with different meanings will lie far away. You can use the [Cohere's Embed Playground](https://dashboard.cohere.com/playground/embed) to visualize embeddings in two dimensions.\n",
    "\n",
    "To provide with the most relevant chunks, we can use the embeddings of the question and the chunks of the transcription to compute the similarity between them. We can then select the chunks with the highest similarity to the question and use them as the context for the model:\n",
    "\n",
    "<img src='images/system3.png' width=\"1200\">\n",
    "\n",
    "Let's generate embeddings for an arbitrary query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding length: 1536\n",
      "[-0.001322312901851765, -0.03448179162953851, -0.011429287757489132, 0.0012597552696740446, -0.026199156751992487, 0.00912090989612891, -0.01568946523291026, 0.0017563068679863883, -0.0118546804944879, -0.03320561528118725]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "embedded_query = embeddings.embed_query(\"Who is Mary's sister?\")\n",
    "\n",
    "print(f\"Embedding length: {len(embedded_query)}\")\n",
    "print(embedded_query[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate how embeddings work, let's first generate the embeddings for two different sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = embeddings.embed_query(\"Mary's sister is Susana\")\n",
    "sentence2 = embeddings.embed_query(\"Pedro's mother is a teacher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the similarity between the query and each of the two sentences. The closer the embeddings are, the more similar the sentences will be.\n",
    "\n",
    "We can use [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) to calculate the similarity between the query and each of the sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9173914140063472, 0.7679227709517674)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "query_sentence1_similarity = cosine_similarity([embedded_query], [sentence1])[0][0]\n",
    "query_sentence2_similarity = cosine_similarity([embedded_query], [sentence2])[0][0]\n",
    "\n",
    "query_sentence1_similarity, query_sentence2_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a Vector Store\n",
    "\n",
    "We need an efficient way to store document chunks, their embeddings, and perform similarity searches at scale. To do this, we'll use a **vector store**.\n",
    "\n",
    "A vector store is a database of embeddings that specializes in fast similarity searches. \n",
    "\n",
    "<img src='images/system4.png' width=\"1200\">\n",
    "\n",
    "To understand how a vector store works, let's create one in memory and add a few embeddings to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "vectorstore1 = DocArrayInMemorySearch.from_texts(\n",
    "    [\n",
    "        \"Mary's sister is Susana\",\n",
    "        \"John and Tommy are brothers\",\n",
    "        \"Patricia likes white cars\",\n",
    "        \"Pedro's mother is a teacher\",\n",
    "        \"Lucia drives an Audi\",\n",
    "        \"Mary has two siblings\",\n",
    "    ],\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now query the vector store to find the most similar embeddings to a given query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content=\"Mary's sister is Susana\"), 0.9174549036927803),\n",
       " (Document(page_content='Mary has two siblings'), 0.9045440036524318),\n",
       " (Document(page_content='John and Tommy are brothers'), 0.8015357441152158)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore1.similarity_search_with_score(query=\"Who is Mary's sister?\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting the vector store to the chain\n",
    "\n",
    "We can use the vector store to find the most relevant chunks from the transcription to send to the model. Here is how we can connect the vector store to the chain:\n",
    "\n",
    "<img src='images/chain4.png' width=\"1200\">\n",
    "\n",
    "We need to configure a [Retriever](https://python.langchain.com/docs/modules/data_connection/retrievers/). The retriever will run a similarity search in the vector store and return the most similar documents back to the next step in the chain.\n",
    "\n",
    "We can get a retriever directly from the vector store we created before: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Mary's sister is Susana\"),\n",
       " Document(page_content='Mary has two siblings'),\n",
       " Document(page_content='John and Tommy are brothers'),\n",
       " Document(page_content=\"Pedro's mother is a teacher\")]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever1 = vectorstore1.as_retriever()\n",
    "retriever1.invoke(\"Who is Mary's sister?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our prompt expects two parameters, \"context\" and \"question.\" We can use the retriever to find the chunks we'll use as the context to answer the question.\n",
    "\n",
    "We can create a map with the two inputs by using the [`RunnableParallel`](https://python.langchain.com/docs/expression_language/how_to/map) and [`RunnablePassthrough`](https://python.langchain.com/docs/expression_language/how_to/passthrough) classes. This will allow us to pass the context and question to the prompt as a map with the keys \"context\" and \"question.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='Patricia likes white cars'),\n",
       "  Document(page_content='Lucia drives an Audi'),\n",
       "  Document(page_content=\"Pedro's mother is a teacher\"),\n",
       "  Document(page_content=\"Mary's sister is Susana\")],\n",
       " 'question': \"What color is Patricia's car?\"}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "setup = RunnableParallel(context=retriever1, question=RunnablePassthrough())\n",
    "setup.invoke(\"What color is Patricia's car?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now add the setup map to the chain and run it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'White'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = setup | prompt | model | parser\n",
    "chain.invoke(\"What color is Patricia's car?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's invoke the chain using another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lucia drives an Audi.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What car does Lucia drive?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading transcription into the vector store\n",
    "\n",
    "We initialized the vector store with a few random strings. Let's create a new vector store using the chunks from the video transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore2 = DocArrayInMemorySearch.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up a new chain using the correct vector store. This time we are using a different equivalent syntax to specify the [`RunnableParallel`](https://python.langchain.com/docs/expression_language/how_to/map) portion of the chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, the appeal in this case is dismissed, so it is not approved.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"context\": vectorstore2.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "chain.invoke(\"is this case approved?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Pinecone\n",
    "\n",
    "So far we've used an in-memory vector store. In practice, we need a vector store that can handle large amounts of data and perform similarity searches at scale. For this example, we'll use [Pinecone](https://www.pinecone.io/).\n",
    "\n",
    "The first step is to create a Pinecone account, set up an index, get an API key, and set it as an environment variable `PINECONE_API_KEY`.\n",
    "\n",
    "Then, we can load the transcription documents into Pinecone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/.pyenv/versions/3.9.18/envs/rag/lib/python3.9/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "index_name = \"youtube-rag-index\"\n",
    "\n",
    "pinecone = PineconeVectorStore.from_documents(\n",
    "    documents, embeddings, index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run a similarity search on pinecone to make sure everything works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"It's like high quality audio and you're speaking usually pretty clearly. I don't know what open AI's plans are either. Yeah, there's always fun projects basically. And stable diffusion also is opening up a huge amount of experimentation. I would say in the visual realm and generating images and videos and movies. I'll think like videos now. And so that's going to be pretty crazy. That's going to almost certainly work and it's going to be really interesting when the cost of content creation is going to fall to zero. You used to need a painter for a few months to paint a thing and now it's going to be speak to your phone to get your video. So Hollywood will start using it to generate scenes, which completely opens up. Yeah, so you can make a movie like Avatar eventually for under a million dollars. Much less. Maybe just by talking to your phone. I mean, I know it sounds kind of crazy. And then there'd be some voting mechanism. Like how do you have a, like, would there be a show on\", metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content=\"get to another celebrity and might get into other big accounts. And then it'll just, so with just that simple goal, get them to respond. Yeah. Maximize the probability of actual response. Yeah, I mean, you could prompt a powerful model like this with their, it's opinion about how to do any possible thing you're interested in. So they will check us. They're kind of on track to become these oracles. I could sort of think of it that way. They are oracles currently is just text, but they will have calculators, they will have access to Google search, they will have all kinds of gadgets and gizmos, they will be able to operate the internet and find different information. And yeah, in some sense, that's kind of like currently what it looks like in terms of the development. Do you think it'll be an improvement eventually over what Google is for access to human knowledge? Like it'll be a more effective search engine to access human knowledge. I think there's definitely scope in building a\", metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content=\"space but in the digital space it just feels like it's going to be very tricky. Very tricky to out because it seems to be pretty low cost to fake stuff. What are you going to put an AI in jail for like trying to use a fake personhood proof? I mean okay fine you'll put a lot of AI in jail but there'll be more AI's like exponentially more. The cost of creating bought is very low. Unless there's some kind of way to track accurately like you're not allowed to create any program without showing tying yourself to that program. Like any program that runs on the internet you'll be able to trace every single human program that was involved with that program. Yeah maybe you have to start declaring when you know we have to start drawing those boundaries and keeping track of okay what are digital entities versus human entities and what is the ownership of human entities and digital entities and something like that. I don't know but I think I'm optimistic that this is possible and in some sense\", metadata={'source': 'transcription.txt'})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.similarity_search(\"What is Hollywood going to start doing?\")[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's setup the new chain using Pinecone as the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hollywood is going to start using AI to generate scenes for movies.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"context\": pinecone.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "chain.invoke(\"What is Hollywood going to start doing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
